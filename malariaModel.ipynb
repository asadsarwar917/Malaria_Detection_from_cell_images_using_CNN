{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"malaria.ipynb","provenance":[{"file_id":"1uDUEBkm4ePj3CRqC4aKfPaqdI3_Rp2VQ","timestamp":1609516572730}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"5w34wZEIJQvH"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","\r\n","!unzip \"/content/gdrive/My Drive/malaria/cell_images.zip\"\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4BfbJSEJYI-"},"source":["import numpy as np\r\n","import pandas as pd\r\n","import seaborn as sns\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib.image as imread"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZFjW9yCtOgb"},"source":["# # Creating Train / Val / Test folders (One time use)\r\n","import os\r\n","import shutil\r\n","import random\r\n","root_dir = '/content/cell_images/' # data root path\r\n","classes_dir = ['Parasitizied', 'Uninfected'] #total labels\r\n","\r\n","#val_ratio = 0.15\r\n","test_ratio = 0.1\r\n","\r\n","for cls in classes_dir:\r\n","    os.makedirs(root_dir +'train/' + cls)\r\n","    #os.makedirs(root_dir +'val/' + cls)\r\n","    os.makedirs(root_dir +'test/' + cls)\r\n","\r\n","\r\n","# Creating partitions of the data after shuffeling\r\n","src = root_dir + cls # Folder to copy images from\r\n","\r\n","allFileNames = os.listdir(src)\r\n","np.random.shuffle(allFileNames)\r\n","train_FileNames, test_FileNames = np.split(np.array(allFileNames),\r\n","                                                          [int(len(allFileNames)* (1 - test_ratio))])\r\n","\r\n","\r\n","train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\r\n","#val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\r\n","test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\r\n","\r\n","print('Total images: ', len(allFileNames))\r\n","print('Training: ', len(train_FileNames))\r\n","#print('Validation: ', len(val_FileNames))\r\n","print('Testing: ', len(test_FileNames))\r\n","\r\n","# Copy-pasting images\r\n","for name in train_FileNames:\r\n","    shutil.copy(name, root_dir +'train/' + cls)\r\n","\r\n","#for name in val_FileNames:\r\n","#    shutil.copy(name, root_dir +'val/' + cls)\r\n","\r\n","for name in test_FileNames:\r\n","    shutil.copy(name, root_dir +'test/' + cls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1TSk4VKKV5Z"},"source":["test_path = 'cell_images/test/'\r\n","train_path = 'cell_images/train/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fcSbb3fKYSM"},"source":["import tensorflow\r\n","print(tensorflow.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X80mnWn6Ka0U"},"source":["from IPython.display import clear_output\r\n","\r\n","from tensorflow.keras.optimizers import SGD, Adam, Adadelta\r\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization ,Dropout\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.callbacks import Callback\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfhaSSMAKfxU"},"source":["image_size = (150, 150) #Image size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ya9qEiqkKija"},"source":["datagen = ImageDataGenerator(\r\n","    rotation_range=20,\r\n","    width_shift_range=0.10, # Shift the pic width by a max of 5%\r\n","    height_shift_range=0.10, # Shift the pic height by a max of 5%\r\n","    rescale=1/255, # Rescale the image by normalzing it.\r\n","    shear_range=0.1, # Shear means cutting away part of the image (max 10%)\r\n","    zoom_range=0.1, # Zoom in by 10% max\r\n","    horizontal_flip=True, # Allo horizontal flipping\r\n","    fill_mode='nearest' # Fill in missing pixels with the nearest filled value\r\n",")\r\n","\r\n","train_gen = datagen.flow_from_directory(\r\n","    train_path,\r\n","    target_size=image_size,\r\n","    batch_size=16,\r\n","    color_mode='rgb',\r\n","    class_mode='binary',\r\n","    shuffle=True\r\n",")\r\n","\r\n","validation_gen = datagen.flow_from_directory(\r\n","    test_path,\r\n","    target_size=image_size,\r\n","    batch_size=16,\r\n","    class_mode='binary',\r\n","    shuffle=False,\r\n","    color_mode='rgb'\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfvcmRmvKmMn"},"source":["train_gen.class_indices   #Lables"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-asLf8S9xXfW"},"source":["class PlotLearning(Callback):\r\n","    def on_train_begin(self, logs={}):\r\n","        self.i = 0\r\n","        self.x = []\r\n","        self.losses = []\r\n","        self.val_losses = []\r\n","        self.acc = []\r\n","        self.val_acc = []\r\n","        self.fig = plt.figure()\r\n","        \r\n","        self.logs = []\r\n","        \r\n","\r\n","    def on_epoch_end(self, epoch, logs={}):\r\n","        \r\n","        self.logs.append(logs)\r\n","        self.x.append(self.i)\r\n","        self.losses.append(logs.get('loss'))\r\n","        self.val_losses.append(logs.get('val_loss'))\r\n","        self.acc.append(logs.get('acc'))\r\n","        self.val_acc.append(logs.get('val_acc'))\r\n","        self.i += 1\r\n","        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\r\n","        \r\n","        clear_output(wait=True)\r\n","        \r\n","        ax1.set_yscale('Log')\r\n","        ax1.plot(self.x, self.losses, label=\"loss\")\r\n","        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\r\n","        ax1.legend()\r\n","        \r\n","        ax2.plot(self.x, self.acc, label=\"acc\")\r\n","        ax2.plot(self.x, self.val_acc, label=\"val_acc\")\r\n","        ax2.legend()\r\n","        \r\n","        plt.show()\r\n","        \r\n","        \r\n","plot = PlotLearning()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZsFyBP2xjGY"},"source":["model = Sequential()\r\n","\r\n","model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=image_size+(3,), activation='relu'))\r\n","model.add(MaxPooling2D(pool_size=(2,2)))\r\n","\r\n","model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=image_size+(3,), activation='relu'))\r\n","model.add(MaxPooling2D(pool_size=(2,2)))\r\n","\r\n","model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=image_size+(3,), activation='relu'))\r\n","model.add(MaxPooling2D(pool_size=(2,2)))\r\n","\r\n","model.add(Flatten())\r\n","\r\n","model.add(Dense(128, activation='relu'))\r\n","model.add(Dropout(0.5))\r\n","\r\n","model.add(Dense(1, activation='sigmoid'))\r\n","\r\n","\r\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eV7d6AUFxmlS"},"source":["model.summary()  # Summary of the model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVro9L5QxqCe"},"source":["model.fit_generator(train_gen, epochs=20, callbacks=[plot], validation_data=validation_gen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zD57gh-fxu7M"},"source":["model.save('malariaModel.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqZdXc-0x1lT"},"source":["model.evaluate_generator(validation_gen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i269lKmAx4W2"},"source":["model.metrics_names"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AcH3YfdJZYsA"},"source":["Reloaded model"]},{"cell_type":"code","metadata":{"id":"yq-sJOcdZb49"},"source":["import tensorflow\r\n","reloaded_model=tensorflow.keras.models.load_model(\"/content/malariaModel.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7BwhVAfXx70g"},"source":["import numpy as np\r\n","from google.colab import files\r\n","from keras.preprocessing import image\r\n","\r\n","uploaded = files.upload()\r\n","\r\n","for fn in uploaded.keys():\r\n"," \r\n","  # predicting images\r\n","  path = fn\r\n","  img = image.load_img(path, target_size=(130, 130))\r\n","  x = image.img_to_array(img)\r\n","  x = np.expand_dims(x, axis=0)\r\n","\r\n","  images = np.vstack([x])\r\n","  classes = reloaded_model.predict(images, batch_size=10)\r\n","  #print(fn)\r\n","  print(classes[0])"],"execution_count":null,"outputs":[]}]}